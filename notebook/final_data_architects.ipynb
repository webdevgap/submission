{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He35xXI9nq-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95620f69-b2f3-403f-a1f7-8e9b4d7f3fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect Colab to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify GPU access\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "uILIhCHyy28U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all important libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "metadata": {
        "id": "aRsBZf8D76q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "GEBOfo7s8TMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoilDataset(Dataset):\n",
        "    def __init__(self, root_dir, csv_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(self.df['soil_type'].unique())\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      img_name = os.path.join(self.root_dir, self.df.iloc[idx]['image_id'])\n",
        "      image = Image.open(img_name).convert('RGB')\n",
        "      label = self.class_to_idx[self.df.iloc[idx]['soil_type']]\n",
        "      if self.transform:\n",
        "        image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "6KxTaoR68ae-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_DIR = '/content/drive/MyDrive/soil_classification'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "full_dataset = SoilDataset(\n",
        "    root_dir='/content/drive/MyDrive/soil_classification/train',\n",
        "    csv_file='/content/drive/MyDrive/soil_classification/train_labels.csv',\n",
        "    transform=train_transform\n",
        ")"
      ],
      "metadata": {
        "id": "ZJPejctI_4Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "indices = np.arange(len(full_dataset))\n",
        "stratify_labels = full_dataset.df['soil_type'].values"
      ],
      "metadata": {
        "id": "QPPvVxT-Be4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx, val_idx = train_test_split(\n",
        "    indices,\n",
        "    test_size=0.2,\n",
        "    stratify=stratify_labels,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "ns_l4cgTBjfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Subset(full_dataset, train_idx)\n",
        "val_dataset = Subset(full_dataset, val_idx)\n",
        "val_dataset.dataset.transform = val_transform"
      ],
      "metadata": {
        "id": "M4mFPm9BBqD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train transform:\", train_dataset.dataset.transform)\n",
        "print(\"Val transform:\", val_dataset.dataset.transform)"
      ],
      "metadata": {
        "id": "QCtrTk2TBsa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        "    Subset,\n",
        "    WeightedRandomSampler\n",
        ")"
      ],
      "metadata": {
        "id": "TQtvKYQgJBeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = full_dataset.df['soil_type'].value_counts().sort_index()\n",
        "class_weights = 1. / torch.tensor(class_counts.values, dtype=torch.float)\n",
        "\n",
        "train_labels = stratify_labels[train_idx]\n",
        "sample_weights = class_weights[torch.tensor([\n",
        "    full_dataset.class_to_idx[cls] for cls in train_labels\n",
        "])]\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")"
      ],
      "metadata": {
        "id": "iRv2p8gRFDs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=sampler,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "cmGrtdzLJMTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(full_dataset.classes))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "3-vLuCqGJNpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "class_weights = class_weights.to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5)"
      ],
      "metadata": {
        "id": "S70tiVNiiKp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "class_weights = class_weights.to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5)\n"
      ],
      "metadata": {
        "id": "X6YcVs34ifwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "best_f1 = 0.0\n",
        "for epoch in range(25):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    val_loss /= len(val_loader)\n",
        "    val_f1 = f1_score(all_labels, all_preds, average=None)\n",
        "    min_f1 = np.min(val_f1)\n",
        "\n",
        "    scheduler.step(min_f1)\n",
        "\n",
        "    if min_f1 > best_f1:\n",
        "        best_f1 = min_f1\n",
        "        torch.save(model.state_dict(), os.path.join(SAVE_DIR, 'best_model.pth'))\n",
        "\n",
        "    print(f'\\nEpoch {epoch+1} Summary:')\n",
        "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
        "    print('Class-wise F1 Scores:')\n",
        "    for cls, score in zip(full_dataset.classes, val_f1):\n",
        "        print(f'  {cls}: {score:.4f}')\n",
        "    print(f'Minimum F1: {min_f1:.4f}')\n"
      ],
      "metadata": {
        "id": "n0u7rKRQjHFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, img_dir, csv_path, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_dir (string): Path to directory with test images\n",
        "            csv_path (string): Path to CSV file with 'image_id' column\n",
        "            transform (callable): Optional transform to apply\n",
        "        \"\"\"\n",
        "        self.img_dir = img_dir\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Verify required columns\n",
        "        if 'image_id' not in self.df.columns:\n",
        "            raise ValueError(\"CSV must contain 'image_id' column\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.df.iloc[idx]['image_id'])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, self.df.iloc[idx]['image_id']  # Return image + original ID"
      ],
      "metadata": {
        "id": "o8r07VDMCjei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set paths (update with your actual paths)\n",
        "TEST_DIR = '/content/drive/MyDrive/soil_classification/test'\n",
        "TEST_CSV = '/content/drive/MyDrive/soil_classification/test_ids.csv'\n",
        "\n",
        "# Create dataset and loader\n",
        "test_dataset = TestDataset(\n",
        "    img_dir=TEST_DIR,\n",
        "    csv_path=TEST_CSV,\n",
        "    transform=val_transform  # Same as validation transforms\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "l_6qYB8ECpnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "image_ids = []\n",
        "all_outputs = []  # NEW: Store all model outputs\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, ids in tqdm(test_loader):\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Store all relevant data\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        image_ids.extend(ids)\n",
        "        all_outputs.extend(outputs.cpu())  # NEW: Save all outputs"
      ],
      "metadata": {
        "id": "zBMpRDv7C3WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now process outputs together\n",
        "confidences = [\n",
        "    torch.nn.functional.softmax(output, dim=0)[pred].item()\n",
        "    for output, pred in zip(all_outputs, predictions)\n",
        "]\n",
        "\n",
        "# Verify lengths match\n",
        "assert len(image_ids) == len(predictions) == len(confidences), \\\n",
        "    f\"Length mismatch: {len(image_ids)} ids, {len(predictions)} preds, {len(confidences)} confs\"\n",
        "\n",
        "# Create DataFrame\n",
        "results = pd.DataFrame({\n",
        "    'image_id': image_ids,\n",
        "    'predicted_class': [full_dataset.classes[p] for p in predictions],\n",
        "    'confidence': confidences\n",
        "})\n",
        "\n",
        "results.to_csv(os.path.join(SAVE_DIR, 'test_predictions.csv'), index=False)"
      ],
      "metadata": {
        "id": "4b6KI5KcDONk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}